---
layout: page
permalink: /2026/submissions/
title: Call for Papers
edition: 2026
nav: true
nav_order: 2
---

Over the last decade, deep learning has brought about astonishing improvements in computer vision, signal processing, language modeling and beyond.
The complexity of real high-dimensional data and deep network architectures used in practice stands as a challenge to traditional mathematical analysis, which is limited to simplified, tractable models that can be analyzed rigorously from the bottom up.
Hence, many aspects remain mysterious and our understanding of the success and failure modes of deep learning remains very limited.

This workshop aims to promote a complementary approach to further our understanding of deep learning, through the lens of the scientific method. This approach relies on a **tight interaction between carefully designed experiments and theoretical models** in order to answer precise questions about how and why deep learning works.
<!-- For instance, it can be used to validate or falsify hypotheses, challenge common assumptions, evidence surprising phenomena, or reveal empirical regularities. -->
<!-- Such results can then be used to ground theoretical models in empirical observations or formulate conjectures, but also can inform engineering decisions and spur new research directions. -->

### Submission Topics

We invite researchers from machine learning and related fields to submit their latest work on the science of deep learning to the workshop. Accepted papers will be presented as posters during the poster sessions. Selected works will also be highlighted as contributed talks.

We encourage submissions that further our understanding of deep learning using the scientific method. **In particular, we expect submissions to either conduct, rely on, or inform empirical experiments on real-world datasets.** Papers that are a good fit for the workshop typically aim to do one or more of the following:
* validate or falsify hypotheses about the inner workings of deep networks,
* report observations to inform or inspire theoretical models,
* evidence new phenomena or empirical regularities (e.g., scaling laws),
* propose minimal analytical models that explain observed phenomena,
* develop controlled experimental settings to facilitate further empirical investigations,
* reproduce prior empirical results in simplified or extended settings,
* introduce new experimental tools and methodologies for studying deep learning.

We invite studies that employ the scientific method of investigation in any field of application, including but not limited to:
* data modalities: vision, language, ...
* network architectures: CNNs, transformers, ...
* tasks: (self)-supervised learning, generative models, ...
* object of study: training dynamics, loss landscapes, weights, representations, ...

**We explicitly welcome submissions that fall outside standard acceptance criteria** (improving state-of-the-art performance, proving rigorous theorems, ...) yet have a high impact potential by **furthering our understanding of deep learning**.

<!-- We invite submissions that advance our scientific understanding of deep learning through:

1. **Empirical Studies**: Systematic investigations of neural network behavior, training dynamics, or architectural choices
2. **Theoretical Analysis**: Mathematical frameworks for understanding deep learning phenomena
3. **Mechanistic Interpretability**: Methods for reverse-engineering learned algorithms and representations
4. **Reproducibility Studies**: Rigorous replications and extensions of prior work
5. **Methodology**: New experimental or analytical techniques for studying deep learning -->


## Challenge

TODO

<!-- Authors can opt-in to be included to our **Debunking Challenge**, a competition aiming to interrogate commonly-held beliefs in the deep learning community. **Authors may add an additional page to their submission to submit to the challenge**. Prizes will be awarded to the top submission. For full details and submission criteria please visit [our Challenge page](/challenge/). -->


### Important Dates

- **Submission deadline**: January 30 ‘26 (Anywhere on Earth)
- **Acceptance notification**: March 1 ‘26 (Anywhere on Earth)
- **Workshop date**: April 26 or 27 ‘26

## Submission Details

To ensure your submission is considered, please adhere to the following guidelines:

* **Formatting Instructions**: Submissions are limited to 4 pages, with unlimited additional pages for references and appendices. **Please use [this LaTeX style files template](/assets/files/styles2026.zip)**.
* **Reviews**: The review process will be double-blind. **All submissions must be anonymized**. Submissions that breach anonymity will be desk-rejected.
* **Dual Submission Policy**: If the submission was accepted at prior conferences, journal, or workshops **(including ICLR 2026)**, it should be extended and include new results to be considered for acceptance.  Depending on space constraints, we might open a special _conference to workshop_ track for such submissions. Papers that are currently under review are however welcome to be submitted.
* There will be no proceedings for the venue. Accepted submissions will be made public on OpenReview.
* Submissions will be reviewed on OpenReview: submission page coming soon!

## Call for Reviewers

We are seeking reviewers with expertise in the scientific investigation of deep networks to help us evaluate submissions. If you are interested in reviewing, please fill out this [form](https://forms.gle/YourFormLinkHere). **To ensure a high-quality review process, we have reserved monetary awards for outstanding reviewers.**

<!-- To apply for financial assistance fill out this [form](https://forms.gle/mANcM9ZkS7q7BCof7). -->

### Questions?

For any questions, please contact us at: [scienceofdl.workshop@gmail.com](mailto:scienceofdl.workshop@gmail.com)
